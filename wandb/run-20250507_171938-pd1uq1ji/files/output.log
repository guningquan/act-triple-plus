Found 80 hdf5 files


Data from: ['/home/robot/Dataset_and_Checkpoint/dataset/zip_tie_random']
- Train on [79] episodes
- Test on [1] episodes


Found 80 hdf5 files
Norm stats from: ['/home/robot/Dataset_and_Checkpoint/dataset/zip_tie_random']
Initializing transformations
Initializing transformations
Augment images: False, train_num_workers: 2, val_num_workers: 2
/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
camera_name cam_left_wrist
camera_name cam_right_wrist
Use VQ: False, None, None
******************************************************************************************************************************************************
number of parameters: 117.43M
KL Weight 10
  0%|                                                                                                                                                                  | 0/100001 [00:01<?, ?it/s]
Validating
img.shape is torch.Size([4, 3, 480, 640])
img_rescaled.shape is torch.Size([4, 3, 256, 256])
normals.shape is torch.Size([4, 8, 16, 16])
normals_resized.shape is torch.Size([4, 8, 480, 640])
Traceback (most recent call last):
  File "imitate_episodes_multi_gpu.py", line 904, in <module>
    main(vars(parser.parse_args()))
  File "imitate_episodes_multi_gpu.py", line 233, in main
    best_ckpt_info = train_bc(train_dataloader, val_dataloader, config, policy)
  File "imitate_episodes_multi_gpu.py", line 797, in train_bc
    forward_dict = forward_pass(data, policy)
  File "imitate_episodes_multi_gpu.py", line 744, in forward_pass
    return policy(qpos_data, image_data, action_data, is_pad) # TODO remove None
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/policy.py", line 343, in __call__
    a_hat, is_pad_hat, (mu, logvar), probs, binaries = self.model(qpos, image, env_state, actions, is_pad, vq_sample)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/detr_vae.py", line 164, in forward
    features, pos = self.backbones[cam_id](image[:, cam_id])
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 150, in forward
    xs = self[0](tensor_list)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 203, in forward
    return self.backbone(normals_resized)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 121, in forward
    xs = self.body(tensor)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torchvision/models/_utils.py", line 69, in forward
    x = module(x)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[4, 8, 480, 640] to have 3 channels, but got 8 channels instead
Traceback (most recent call last):
  File "imitate_episodes_multi_gpu.py", line 904, in <module>
    main(vars(parser.parse_args()))
  File "imitate_episodes_multi_gpu.py", line 233, in main
    best_ckpt_info = train_bc(train_dataloader, val_dataloader, config, policy)
  File "imitate_episodes_multi_gpu.py", line 797, in train_bc
    forward_dict = forward_pass(data, policy)
  File "imitate_episodes_multi_gpu.py", line 744, in forward_pass
    return policy(qpos_data, image_data, action_data, is_pad) # TODO remove None
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/policy.py", line 343, in __call__
    a_hat, is_pad_hat, (mu, logvar), probs, binaries = self.model(qpos, image, env_state, actions, is_pad, vq_sample)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/detr_vae.py", line 164, in forward
    features, pos = self.backbones[cam_id](image[:, cam_id])
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 150, in forward
    xs = self[0](tensor_list)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 203, in forward
    return self.backbone(normals_resized)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/robot/Programs_Codes/aloha_related/act-triple-plus/detr/models/backbone.py", line 121, in forward
    xs = self.body(tensor)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torchvision/models/_utils.py", line 69, in forward
    x = module(x)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu20/miniforge3/envs/aloha/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[4, 8, 480, 640] to have 3 channels, but got 8 channels instead
